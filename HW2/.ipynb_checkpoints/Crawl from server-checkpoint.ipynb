{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pyquery import PyQuery as pq\n",
    "import time\n",
    "import datetime\n",
    "import requests\n",
    "import urllib.request\n",
    "import os\n",
    "import calendar\n",
    "import pickle\n",
    "from lxml import etree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('search_addr_final.pkl','rb') as f:\n",
    "    search_addr = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tickers = pd.read_csv('all_ticker.csv').iloc[:,1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('./10-Q_url/company_ft_dic_final.pkl','rb') as f:\n",
    "    company_ft_dic = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def crawl_fp_txt_url(company_url):\n",
    "    finance_report_url = []\n",
    "    res = requests.get(company_url)\n",
    "    doc = pq(res.text)\n",
    "\n",
    "    temp = 'https://www.sec.gov'\n",
    "    for i,d in enumerate(doc('.tableFile2 #documentsbutton').items()):\n",
    "\n",
    "        f_url = temp+d.attr('href')    \n",
    "        lv1_res = requests.get(f_url)\n",
    "        lv1_doc = pq(lv1_res.text)\n",
    "        txt_num = lv1_doc('#secNum').text().split(' ')[-1]\n",
    "        sel = etree.HTML(lv1_res.text)\n",
    "        txt_url = sel.xpath(f\"//a[contains(text(),'{txt_num}.txt')] \")[0].attrib['href']\n",
    "        finance_report_url.append(txt_url)\n",
    "        \n",
    "    if (len(finance_report_url) == 0):\n",
    "        finance_report_url = 'Unfounded'\n",
    "        \n",
    "    return finance_report_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_finace_report_txt(finance_report_url):\n",
    "    # check directory\n",
    "    if not os.path.isdir('./data'):\n",
    "        os.mkdir('./data')\n",
    "    \n",
    "    for url in finance_report_url:\n",
    "        symbol = url.split('/')[6] # number of company\n",
    "        year = url.split('-')[1]  # 94 ~ 18\n",
    "        filename = './data/' + symbol + '_' + year + 'txt'\n",
    "        urllib.request.urlretrieve(url,filename)\n",
    "        print(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_all_fp_url(tickers,company_addr):\n",
    "    # check directory\n",
    "    if not os.path.isdir('./fp_url'):\n",
    "        os.mkdir('./fp_url')\n",
    "    \n",
    "    # check files\n",
    "    files = os.listdir('./fp_url')\n",
    "    max_ver = 0\n",
    "\n",
    "    for f in files:\n",
    "        if 'company' in f:\n",
    "            version = int(f.split('_')[3].split('.')[0])\n",
    "            if (version > max_ver ):\n",
    "                max_ver = version\n",
    "                max_f = f\n",
    "    if (max_ver == 0):     \n",
    "        company_fp_dic = {}\n",
    "    else:\n",
    "        if (os.path.getsize(f\"./fp_url/{max_f}\") > 0):\n",
    "            with open(f'./fp_url/{max_f}','rb') as f:\n",
    "                company_fp_dic = pickle.load(f)\n",
    "        else:\n",
    "            company_fp_dic = {}\n",
    "    length = len(company_fp_dic)   \n",
    "    \n",
    "    for i,key in enumerate(tickers[length:]):\n",
    "        addr = company_addr[key]\n",
    "        \n",
    "        if (addr != 'Unfounded'):\n",
    "            fp_addr = crawl_fp_txt_url(addr)\n",
    "            company_fp_dic[key] = fp_addr\n",
    "        else:\n",
    "            company_fp_dic[key] = 'Unfounded'\n",
    "            \n",
    "        if(len(company_fp_dic)%1000 == 0):\n",
    "            num = len(company_fp_dic)/1000\n",
    "\n",
    "            with open(f\"./fp_url/company_fp_dic_{num}.pkl\",\"wb\") as f:\n",
    "                pickle.dump(company_fp_dic,f)\n",
    "                print(f'./fp_url/company_fp_dic_{num}.pkl',i+length)\n",
    "                \n",
    "    with open(f\"./fp_url/company_fp_dic_final.pkl\",\"wb\") as f:\n",
    "        pickle.dump(company_fp_dic,f)\n",
    "        print(f'./fp_url/company_fp_dic_final.pkl',i+length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./fp_url/company_fp_dic_1.0.pkl 999\n"
     ]
    }
   ],
   "source": [
    "get_all_fp_url(tickers,company_ft_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
